#!/usr/bin/env bash

################################################################################
# REPOSITORY MANAGEMENT
################################################################################

#
# Source for packages (accumulo, hadoop, etc)
# Available options are (local, wget)
#
# Set the variable 'pkg_src_mirror' if you want to specify a mirror
# else it will use https://www.apache.org/dyn/closer.cgi to determine
# a mirror. If you have a caching web proxy you may want to set this as well.
#
# pkg_src_mirror="http://apache.mirrors.tds.net"

# Specify a maven repository to use
pkg_src_maven="https://repo1.maven.org/maven2"

# Optionally specifcy a local shared folder of package downloads
#pkg_pre_download=/net/synds1/volume2/projects2/cloud-local/packages

################################################################################
# VERSION MANAGEMENT - Versions of popular software
################################################################################

pkg_accumulo_ver="2.0.0"
pkg_hbase_ver="1.3.1"
# Note pkg_spark_hadoop_ver below if modifying
pkg_hadoop_ver="3.2.1"
# Note, just the major+minor from Hadoop, not patch level
hadoop_base_ver=${pkg_hadoop_ver:0:3}


pkg_zookeeper_ver="3.4.10"
# Note convention is scala.version_kafka.version
pkg_kafka_scala_ver="2.11"
pkg_kafka_ver="1.0.1"

pkg_spark_ver="2.2.1"
# Note pkg_hadoop_ver above
#  - don't auto-derive this as spark & hadoop major releases aren't lock-step
#  - use "without-hadoop" to use version without hadoop deps
pkg_spark_hadoop_ver="without-hadoop"

pkg_geomesa_ver="1.3.3"
pkg_geomesa_scala_ver="2.11"
pkg_scala_ver="2.11.7"

# Apache Zeppelin, yet another analyst notebook that knows about Spark
# You must change Spark to a compatible version (e.g. Zep 0.7.2 with Spark 2.1 and Zep 0.7.3 with Spark 2.2)
pkg_zeppelin_ver="0.7.3"

################################################################################
# ACCUMULO CONFIGURATION
################################################################################

cl_acc_inst_name="local"
cl_acc_inst_pass="secret"

################################################################################
# IP/HOSTNAME/PORT CONFIGURATION - How to bind to things
################################################################################

# The following options can be overriden in the user environment
# bind address and hostname to use for all service bindings
if [[ -z "${CL_HOSTNAME}" ]]; then
  #CL_HOSTNAME=localhost
  CL_HOSTNAME=$(hostname)
fi

if [[ -z "${CL_BIND_ADDRESS}" ]]; then
  #CL_BIND_ADDRESS="127.0.0.1"
  CL_BIND_ADDRESS=$(hostname -i)
fi

if [[ -z "${CL_PORT_OFFSET}" ]]; then
  CL_PORT_OFFSET=0
fi

if [[ -z "${CL_VERBOSE}" ]]; then
  CL_VERBOSE=0
fi

################################################################################
# PACKAGE MANAGEMENT - Enable/Disable software here
################################################################################

# 1 = enabled
# 0 = disabled

master_enabled=1
worker_enabled=1

# Hadoop HDFS and YARN
hadoop_enabled=1

# Enable accumulo or hbase - probably best not to run both but it might work
# Requires hadoop_enabled=1
acc_enabled=1
hbase_enabled=0

# Enable/disable Kafka
kafka_enabled=0

# Download spark distribution
spark_enabled=0

# Enable/Disable installation of GeoMesa
geomesa_enabled=0
if [[ -z "${pkg_geomesa_ver}" && -z "${pkg_geomesa_scala_ver}" && "${geomesa_enabled}" -eq "1" ]]; then
  echo "Error: GeoMesa is enabled but the version number is missing."
	exit 1
fi

# Enable/Disable scala download
scala_enabled=1
if [[ -z "${pkg_scala_ver}" && "${scala_enabled}" -eq "1" ]]; then
  echo "Error: Scala is enabled but the version number is missing."
  exit 1
fi

# Enable/Disable Zepplin
# Ensure that your Spark+Zeppelin versions are compatible
zeppelin_enabled=0
